Starting Graph Generator Suite...
Ensure matplotlib is installed (pip install matplotlib)

============================================================
TEST A: Write Latency vs. Write Quorum (W)
Objective: Demonstrate Asynchronous W-Quorum benefits
Configuration: 100 Nodes, 10 Datacenters
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 100 PUTs with W=1...
[Result] W=1: Avg Latency = 12.26 ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 100 PUTs with W=2...
[Result] W=2: Avg Latency = 13.20 ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 100 PUTs with W=3...
[Result] W=3: Avg Latency = 14.77 ms
[Teardown] Stopping cluster...

[Summary] Write Latency vs W:
W | Latency (ms)
--|-------------
1 | 12.26
2 | 13.20
3 | 14.77

[Graph] Saved plot to graph_report/graph_latency_vs_w.png

============================================================
TEST B: Read Latency vs. Read Quorum (R)
Objective: Quantify the cost of strong consistency (R)
Configuration: 100 Nodes, N=3
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Setup] Populating 100 items...
[Bench] Running 100 GETs with R=1...
[Result] R=1: Avg Latency = 5.97 ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Setup] Populating 100 items...
[Bench] Running 100 GETs with R=2...
[Result] R=2: Avg Latency = 6.31 ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Setup] Populating 100 items...
[Bench] Running 100 GETs with R=3...
[Result] R=3: Avg Latency = 8.07 ms
[Teardown] Stopping cluster...

[Summary] Read Latency vs R:
R | Latency (ms)
--|-------------
1 | 5.97
2 | 6.31
3 | 8.07

[Graph] Saved plot to graph_report/graph_latency_vs_r.png

============================================================
TEST C: System Throughput vs. Concurrency
Objective: Measure scalability and identify bottlenecks
Configuration: 100 Nodes, N=3, R=2, W=2
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 15s throughput test with 1 threads...
[Result] 1 Threads: 74.68 OPS (Total: 1121, Errors: 534)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 15s throughput test with 5 threads...
[Result] 5 Threads: 569.41 OPS (Total: 8548, Errors: 979)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 15s throughput test with 10 threads...
[Result] 10 Threads: 1073.07 OPS (Total: 16107, Errors: 1052)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 15s throughput test with 20 threads...
[Result] 20 Threads: 1297.83 OPS (Total: 19492, Errors: 1010)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Running 15s throughput test with 40 threads...
[Result] 40 Threads: 1324.62 OPS (Total: 19917, Errors: 987)
[Teardown] Stopping cluster...

[Summary] Throughput vs Concurrency:
Threads | OPS
--------|--------
1       | 74.68
5       | 569.41
10      | 1073.07
20      | 1297.83
40      | 1324.62

[Graph] Saved plot to graph_report/graph_throughput_vs_concurrency.png

============================================================
TEST D: Datacenter Distribution Efficiency
Objective: Compare Replica Placement with vs without DC-Awareness
Configuration: 100 Nodes, 10 Datacenters
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Analysis] Fetching topology from cluster...
Added node localhost:50130 with 150 virtual nodes
Added node localhost:50143 with 150 virtual nodes
Added node localhost:50077 with 150 virtual nodes
Added node localhost:50134 with 150 virtual nodes
Added node localhost:50103 with 150 virtual nodes
Added node localhost:50065 with 150 virtual nodes
Added node localhost:50105 with 150 virtual nodes
Added node localhost:50110 with 150 virtual nodes
Added node localhost:50144 with 150 virtual nodes
Added node localhost:50083 with 150 virtual nodes
Added node localhost:50128 with 150 virtual nodes
Added node localhost:50087 with 150 virtual nodes
Added node localhost:50109 with 150 virtual nodes
Added node localhost:50098 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50154 with 150 virtual nodes
Added node localhost:50133 with 150 virtual nodes
Added node localhost:50157 with 150 virtual nodes
Added node localhost:50078 with 150 virtual nodes
Added node localhost:50081 with 150 virtual nodes
Added node localhost:50093 with 150 virtual nodes
Added node localhost:50140 with 150 virtual nodes
Added node localhost:50084 with 150 virtual nodes
Added node localhost:50095 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
Added node localhost:50150 with 150 virtual nodes
Added node localhost:50151 with 150 virtual nodes
Added node localhost:50091 with 150 virtual nodes
Added node localhost:50085 with 150 virtual nodes
Added node localhost:50071 with 150 virtual nodes
Added node localhost:50127 with 150 virtual nodes
Added node localhost:50131 with 150 virtual nodes
Added node localhost:50096 with 150 virtual nodes
Added node localhost:50159 with 150 virtual nodes
Added node localhost:50116 with 150 virtual nodes
Added node localhost:50120 with 150 virtual nodes
Added node localhost:50070 with 150 virtual nodes
Added node localhost:50064 with 150 virtual nodes
Added node localhost:50147 with 150 virtual nodes
Added node localhost:50072 with 150 virtual nodes
Added node localhost:50149 with 150 virtual nodes
Added node localhost:50139 with 150 virtual nodes
Added node localhost:50099 with 150 virtual nodes
Added node localhost:50123 with 150 virtual nodes
Added node localhost:50122 with 150 virtual nodes
Added node localhost:50086 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50092 with 150 virtual nodes
Added node localhost:50152 with 150 virtual nodes
Added node localhost:50132 with 150 virtual nodes
Added node localhost:50108 with 150 virtual nodes
Added node localhost:50080 with 150 virtual nodes
Added node localhost:50138 with 150 virtual nodes
Added node localhost:50088 with 150 virtual nodes
Added node localhost:50094 with 150 virtual nodes
Added node localhost:50089 with 150 virtual nodes
Added node localhost:50097 with 150 virtual nodes
Added node localhost:50121 with 150 virtual nodes
Added node localhost:50113 with 150 virtual nodes
Added node localhost:50129 with 150 virtual nodes
Added node localhost:50137 with 150 virtual nodes
Added node localhost:50126 with 150 virtual nodes
Added node localhost:50145 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50104 with 150 virtual nodes
Added node localhost:50136 with 150 virtual nodes
Added node localhost:50112 with 150 virtual nodes
Added node localhost:50102 with 150 virtual nodes
Added node localhost:50124 with 150 virtual nodes
Added node localhost:50156 with 150 virtual nodes
Added node localhost:50106 with 150 virtual nodes
Added node localhost:50090 with 150 virtual nodes
Added node localhost:50142 with 150 virtual nodes
Added node localhost:50135 with 150 virtual nodes
Added node localhost:50118 with 150 virtual nodes
Added node localhost:50153 with 150 virtual nodes
Added node localhost:50100 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50119 with 150 virtual nodes
Added node localhost:50107 with 150 virtual nodes
Added node localhost:50125 with 150 virtual nodes
Added node localhost:50101 with 150 virtual nodes
Added node localhost:50115 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50155 with 150 virtual nodes
Added node localhost:50148 with 150 virtual nodes
Added node localhost:50074 with 150 virtual nodes
Added node localhost:50111 with 150 virtual nodes
Added node localhost:50146 with 150 virtual nodes
Added node localhost:50141 with 150 virtual nodes
Added node localhost:50073 with 150 virtual nodes
Added node localhost:50114 with 150 virtual nodes
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50076 with 150 virtual nodes
Added node localhost:50158 with 150 virtual nodes
Added node localhost:50082 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50117 with 150 virtual nodes
Added node localhost:50075 with 150 virtual nodes
Added node localhost:50079 with 150 virtual nodes
[Analysis] Reconstructed ring with 100 nodes

[Analysis] Checking 100 keys with DC-Awareness=ON...

[Analysis] Checking 100 keys with DC-Awareness=OFF...

[Result] Comparative Distribution (N=3):
Unique DCs | Aware (Enhanced) | Unaware (Standard)
-----------|------------------|-------------------
     1     |       0          |       0  
     2     |       0          |       23 
     3     |       100        |       77 

[Graph] Saved plot to graph_report/graph_dc_distribution.png
[Teardown] Stopping cluster...

============================================================
TEST E: Key Load Balancing (Uniformity)
Objective: Check if Consistent Hashing distributes load evenly
Configuration: 100 Nodes, N=3, 1000 Items
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Inserting 1000 keys...
  Inserted 0 keys...
  Inserted 100 keys...
  Inserted 200 keys...
  Inserted 300 keys...
  Inserted 400 keys...
  Inserted 500 keys...
  Inserted 600 keys...
  Inserted 700 keys...
  Inserted 800 keys...
  Inserted 900 keys...
[Bench] Inserted 1000/1000 keys. Waiting for replication...
[Analysis] Reading node storage files...

[Result] Total Replicas Stored: 3000 (Expected ~3000)
[Result] Average Keys per Node: 30.00
[Result] Standard Deviation: 5.28
[Result] Min: 17, Max: 46

[Graph] Saved plot to graph_report/graph_load_balancing.png
[Teardown] Stopping cluster...

============================================================
TEST F: Availability under Datacenter Failure
Objective: Prove survival of a complete DC outage (The Money Shot)
Method: Kill DC1 (10 nodes) mid-operation and measure success rate
============================================================

[Scenario] Testing W=2 (High Availability)...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Bench] Starting continuous operations for 50s...
[Bench] Scheduled to KILL DC1 at t=5s
[EVENT] ⚡ KILLING DATACENTER 1 (Nodes 0-9) ⚡
[Teardown] Stopping cluster...

[Scenario] Testing W=3 (Strong Consistency)...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Bench] Starting continuous operations for 50s...
[Bench] Scheduled to KILL DC1 at t=5s
[EVENT] ⚡ KILLING DATACENTER 1 (Nodes 0-9) ⚡
[Teardown] Stopping cluster...

[Graph] Saved plot to graph_report/graph_availability_dc_failure.png

============================================================
TEST G: Divergent Versions (Conflict) Rate
Objective: Show Vector Clock behavior under realistic race conditions
Method: Concurrent writes with random network jitter
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Simulating 50 concurrent write pairs...

[Graph] Saved improved plot to graph_report/graph_conflict_rate.png
[Teardown] Stopping cluster...

============================================================
TEST H: Read Repair Latency (Convergence Time)
Objective: Measure time for 'Eventual Consistency' to become 'Consistent'
Method: Partition Node -> Write(W=2) -> Reconnect -> Read(R=3) -> Measure Repair
Configuration: 100 Nodes, N=3, R=3, W=2
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
Added node localhost:50156 with 150 virtual nodes
Added node localhost:50120 with 150 virtual nodes
Added node localhost:50146 with 150 virtual nodes
Added node localhost:50080 with 150 virtual nodes
Added node localhost:50137 with 150 virtual nodes
Added node localhost:50086 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
Added node localhost:50081 with 150 virtual nodes
Added node localhost:50122 with 150 virtual nodes
Added node localhost:50155 with 150 virtual nodes
Added node localhost:50091 with 150 virtual nodes
Added node localhost:50141 with 150 virtual nodes
Added node localhost:50082 with 150 virtual nodes
Added node localhost:50125 with 150 virtual nodes
Added node localhost:50148 with 150 virtual nodes
Added node localhost:50129 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50100 with 150 virtual nodes
Added node localhost:50114 with 150 virtual nodes
Added node localhost:50123 with 150 virtual nodes
Added node localhost:50107 with 150 virtual nodes
Added node localhost:50124 with 150 virtual nodes
Added node localhost:50092 with 150 virtual nodes
Added node localhost:50119 with 150 virtual nodes
Added node localhost:50144 with 150 virtual nodes
Added node localhost:50133 with 150 virtual nodes
Added node localhost:50113 with 150 virtual nodes
Added node localhost:50127 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50110 with 150 virtual nodes
Added node localhost:50094 with 150 virtual nodes
Added node localhost:50065 with 150 virtual nodes
Added node localhost:50074 with 150 virtual nodes
Added node localhost:50132 with 150 virtual nodes
Added node localhost:50153 with 150 virtual nodes
Added node localhost:50143 with 150 virtual nodes
Added node localhost:50085 with 150 virtual nodes
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50115 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50130 with 150 virtual nodes
Added node localhost:50075 with 150 virtual nodes
Added node localhost:50096 with 150 virtual nodes
Added node localhost:50071 with 150 virtual nodes
Added node localhost:50087 with 150 virtual nodes
Added node localhost:50098 with 150 virtual nodes
Added node localhost:50097 with 150 virtual nodes
Added node localhost:50117 with 150 virtual nodes
Added node localhost:50138 with 150 virtual nodes
Added node localhost:50064 with 150 virtual nodes
Added node localhost:50145 with 150 virtual nodes
Added node localhost:50136 with 150 virtual nodes
Added node localhost:50147 with 150 virtual nodes
Added node localhost:50104 with 150 virtual nodes
Added node localhost:50116 with 150 virtual nodes
Added node localhost:50121 with 150 virtual nodes
Added node localhost:50126 with 150 virtual nodes
Added node localhost:50095 with 150 virtual nodes
Added node localhost:50134 with 150 virtual nodes
Added node localhost:50159 with 150 virtual nodes
Added node localhost:50103 with 150 virtual nodes
Added node localhost:50128 with 150 virtual nodes
Added node localhost:50101 with 150 virtual nodes
Added node localhost:50135 with 150 virtual nodes
Added node localhost:50088 with 150 virtual nodes
Added node localhost:50090 with 150 virtual nodes
Added node localhost:50139 with 150 virtual nodes
Added node localhost:50102 with 150 virtual nodes
Added node localhost:50142 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50111 with 150 virtual nodes
Added node localhost:50072 with 150 virtual nodes
Added node localhost:50152 with 150 virtual nodes
Added node localhost:50076 with 150 virtual nodes
Added node localhost:50099 with 150 virtual nodes
Added node localhost:50112 with 150 virtual nodes
Added node localhost:50149 with 150 virtual nodes
Added node localhost:50109 with 150 virtual nodes
Added node localhost:50070 with 150 virtual nodes
Added node localhost:50078 with 150 virtual nodes
Added node localhost:50079 with 150 virtual nodes
Added node localhost:50150 with 150 virtual nodes
Added node localhost:50154 with 150 virtual nodes
Added node localhost:50158 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50140 with 150 virtual nodes
Added node localhost:50093 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50084 with 150 virtual nodes
Added node localhost:50089 with 150 virtual nodes
Added node localhost:50073 with 150 virtual nodes
Added node localhost:50157 with 150 virtual nodes
Added node localhost:50083 with 150 virtual nodes
Added node localhost:50077 with 150 virtual nodes
Added node localhost:50106 with 150 virtual nodes
Added node localhost:50118 with 150 virtual nodes
Added node localhost:50131 with 150 virtual nodes
Added node localhost:50105 with 150 virtual nodes
Added node localhost:50151 with 150 virtual nodes
Added node localhost:50108 with 150 virtual nodes

[Bench] Running 20 repair trials...

[Result] Convergence Avg: 6.41 ms

[Graph] Saved plot to graph_report/graph_read_repair.png
[Teardown] Stopping cluster...

============================================================
TEST I: Total Datacenter Failure Survival
Objective: Compare Data Availability after complete DC failure
Scenario: Write 100 keys -> Kill DC1 -> Read 100 keys
Configuration: 100 Nodes, 10 Datacenters
============================================================

[Setup] Cleaning environment...

[Test] Running scenario: Baseline (Naive)

✓ All 30 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Step] Writing 100 keys...
  Written 100 keys. Waiting for replication...
[EVENT] ⚡ DESTROYING DATACENTER 1 ⚡
  Killed 10 nodes (All of DC1). System is degraded.
[Step] Attempting to read keys from remaining DCs...
[Result] Baseline (Naive): 93/100 keys retrieved (93.0%)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Test] Running scenario: Enhanced (DC-Aware)

✓ All 30 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Step] Writing 100 keys...
  Written 100 keys. Waiting for replication...
[EVENT] ⚡ DESTROYING DATACENTER 1 ⚡
  Killed 10 nodes (All of DC1). System is degraded.
[Step] Attempting to read keys from remaining DCs...
[Result] Enhanced (DC-Aware): 100/100 keys retrieved (100.0%)
[Teardown] Stopping cluster...

[Summary] Survival Rate (DC1 Failure):
Baseline (Naive): 93.0%
Enhanced (DC-Aware): 100.0%

[Graph] Saved plot to graph_report/graph_survival_test.png

============================================================
TEST J: Straggler Node Latency
Objective: Prove Asynchronous W-Quorum ignores slow nodes
Scenario: DC3 has 50ms delay. Compare W=3 vs W=2.
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Synchronous (W=3): Performing writes...
  Write 0: 95.8 ms
  Write 1: 64.5 ms
  Write 2: 65.5 ms
  Write 3: 64.2 ms
  Write 4: 64.0 ms
  Write 5: 62.8 ms
  Write 6: 63.2 ms
  Write 7: 64.0 ms
  Write 8: 64.0 ms
  Write 9: 65.1 ms
  Write 10: 65.3 ms
  Write 11: 65.1 ms
  Write 12: 64.8 ms
  Write 13: 64.0 ms
  Write 14: 64.8 ms
  Write 15: 63.7 ms
  Write 16: 64.1 ms
  Write 17: 64.2 ms
  Write 18: 65.8 ms
  Write 19: 64.4 ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...

[Bench] Asynchronous (W=2): Performing writes...
  Write 0: 14.3 ms
  Write 1: 13.2 ms
  Write 2: 12.6 ms
  Write 3: 12.6 ms
  Write 4: 12.7 ms
  Write 5: 12.2 ms
  Write 6: 12.2 ms
  Write 7: 12.6 ms
  Write 8: 11.8 ms
  Write 9: 12.3 ms
  Write 10: 12.3 ms
  Write 11: 12.7 ms
  Write 12: 12.5 ms
  Write 13: 12.4 ms
  Write 14: 12.7 ms
  Write 15: 12.1 ms
  Write 16: 12.3 ms
  Write 17: 12.8 ms
  Write 18: 12.8 ms
  Write 19: 12.3 ms
[Teardown] Stopping cluster...

[Graph] Saved improved plot to graph_report/graph_straggler_latency.png

============================================================
TEST K: Consistency Convergence Speed
Objective: Measure Read Repair efficiency
============================================================

[Setup] Cleaning environment...

✓ All 10 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50065 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50064 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
  Waiting for node_1 to rejoin ring...
[Result] Baseline (No Repair): 50 Stale Reads
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 10 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50065 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50064 with 150 virtual nodes
  Waiting for node_1 to rejoin ring...
[Result] Enhanced (With Repair): 50 Stale Reads
[Teardown] Stopping cluster...

[Graph] Saved improved plot to graph_report/graph_consistency_convergence.png

============================================================
TEST K: Consistency Convergence Speed
Objective: Measure Read Repair efficiency vs Baseline
Scenario: Partition -> Divergent Write -> Reconnect -> Measure Stale Reads
============================================================

[Setup] Cleaning environment...

[Test] Running Baseline (No Repair)...

✓ All 10 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
Added node localhost:50065 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50064 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
[Step] Writing Version_1 to all nodes...
[Step] Killing Node A (node_1)...
[Step] Writing Version_2 to remaining replicas...
[Step] Restarting Node A...
  Waiting for Node A to rejoin ring...
[Step] Measuring Consistency Convergence...
[Result] Baseline (No Repair): 50 Stale / 0 Fresh
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Test] Running Enhanced (With Repair)...

✓ All 10 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50064 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50065 with 150 virtual nodes
[Step] Writing Version_1 to all nodes...
[Step] Killing Node A (node_1)...
[Step] Writing Version_2 to remaining replicas...
[Step] Restarting Node A...
  Waiting for Node A to rejoin ring...
[Step] Measuring Consistency Convergence...
[Result] Enhanced (With Repair): 50 Stale / 0 Fresh
[Teardown] Stopping cluster...

[Graph] Saved plot to graph_report/graph_consistency_convergence.png

============================================================
TEST L: Throughput Scalability: 'Linear Growth'
Objective: Prove Horizontal Scalability (Linear OPS growth with Node count)
Method: Saturation test (40 threads) against cluster sizes 3, 6, 9, 12
============================================================

[Bench] Testing Cluster Size: 3 Nodes (3 trials)...

[Setup] Cleaning environment...

✓ All 3 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 1: 264.80 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 3 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 2: 197.60 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 3 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 3: 0.70 OPS
[Teardown] Stopping cluster...
[Result] Size 3: 154.37 ± 137.26 OPS

[Bench] Testing Cluster Size: 6 Nodes (3 trials)...

[Setup] Cleaning environment...

✓ All 6 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 1: 474.10 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 6 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 2: 473.50 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 6 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 3: 472.20 OPS
[Teardown] Stopping cluster...
[Result] Size 6: 473.27 ± 0.97 OPS

[Bench] Testing Cluster Size: 9 Nodes (3 trials)...

[Setup] Cleaning environment...

✓ All 9 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 1: 592.60 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 9 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 2: 604.60 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 9 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 3: 603.60 OPS
[Teardown] Stopping cluster...
[Result] Size 9: 600.27 ± 6.66 OPS

[Bench] Testing Cluster Size: 12 Nodes (3 trials)...

[Setup] Cleaning environment...

✓ All 12 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 1: 688.40 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 12 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 2: 708.50 OPS
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

✓ All 12 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
  Trial 3: 707.90 OPS
[Teardown] Stopping cluster...
[Result] Size 12: 701.60 ± 11.44 OPS

[Summary] Scalability Results:
Nodes | Throughput (OPS)
------|-----------------
3     | 154.37
6     | 473.27
9     | 600.27
12    | 701.60

[Graph] Saved plot to graph_report/graph_scalability.png

============================================================
TEST M: The 'Availability Cliff' (Time Series)
Objective: Visual proof of Datacenter-Awareness logic
Scenario: Normal Op -> Kill DC1 -> Compare Naive vs Enhanced stability
============================================================

[Setup] Cleaning environment...

[Test] Running Naive Placement...

✓ All 30 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Step] Pre-loading 200 keys...
[Bench] Reading continuously for 15s (Kill at 5s)...
  [EVENT] ⚡ KILLING DC1 ⚡
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Test] Running DC-Aware Placement...

✓ All 30 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Step] Pre-loading 200 keys...
[Bench] Reading continuously for 15s (Kill at 5s)...
  [EVENT] ⚡ KILLING DC1 ⚡
[Teardown] Stopping cluster...

[Graph] Saved plot to graph_report/graph_availability_cliff.png

============================================================
TEST N: Read Repair Convergence Rate
Objective: Visualize 'Eventual Consistency' timeline
============================================================

[Setup] Cleaning environment...

✓ All 10 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
Added node localhost:50064 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50065 with 150 virtual nodes
Added node localhost:50063 with 150 virtual nodes
Added node localhost:50066 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50067 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes

[Graph] Saved improved plot to graph_report/graph_convergence_rate.png
[Teardown] Stopping cluster...

============================================================
TEST O: Load Balance: Virtual Nodes Histogram
Objective: Prove that Virtual Nodes reduce data skew (hot spots)
Configuration: 100 Nodes, N=3, 1000 Items
============================================================

[Setup] Cleaning environment...

[Test] Running Without VNodes (1/node)...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Inserting 1000 keys...
  Inserted 0...
  Inserted 200...
  Inserted 400...
  Inserted 600...
  Inserted 800...
[Result] Without VNodes (1/node): Mean=30.0, StdDev=21.59
  Min=1, Max=117
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Test] Running With VNodes (100/node)...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Inserting 1000 keys...
  Inserted 0...
  Inserted 200...
  Inserted 400...
  Inserted 600...
  Inserted 800...
[Result] With VNodes (100/node): Mean=30.0, StdDev=5.97
  Min=18, Max=47
[Teardown] Stopping cluster...

[Graph] Saved plot to graph_report/graph_vnodes_impact.png

============================================================
TEST P: Conflict Rate vs. Concurrency
Objective: Validate Vector Clocks under increasing pressure
Method: High contention (small key space) with increasing threads
============================================================

[Setup] Cleaning environment...

[Bench] Testing with 1 threads...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Pre-populating 500 keys...
[Bench] Running mixed workload for 10s...
[Result] 1 Threads: 194 Conflicts / 299 Clean (39.4%)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Bench] Testing with 5 threads...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Pre-populating 500 keys...
[Bench] Running mixed workload for 10s...
[Result] 5 Threads: 2605 Conflicts / 473 Clean (84.6%)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Bench] Testing with 10 threads...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Pre-populating 500 keys...
[Bench] Running mixed workload for 10s...
[Result] 10 Threads: 5225 Conflicts / 597 Clean (89.7%)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Bench] Testing with 20 threads...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Pre-populating 500 keys...
[Bench] Running mixed workload for 10s...
[Result] 20 Threads: 5981 Conflicts / 514 Clean (92.1%)
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Bench] Testing with 30 threads...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
[Step] Pre-populating 500 keys...
[Bench] Running mixed workload for 10s...
[Result] 30 Threads: 6731 Conflicts / 495 Clean (93.1%)
[Teardown] Stopping cluster...

[Graph] Saved plot to graph_report/graph_conflict_vs_concurrency.png

============================================================
TEST Q: The Cost of Consistency (R+W Trade-off)
Objective: Visualize the latency 'tax' paid for stronger consistency
Method: Benchmark Read/Write latency across Weak, Balanced, and Strong quorums
============================================================

[Setup] Cleaning environment...

[Test] Testing Config: Weak (R=1, W=1)...

✓ All 25 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Bench] Performing 100 Writes and 100 Reads...
[Result] Weak (R=1, W=1): Write=11.23ms, Read=4.75ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Test] Testing Config: Balanced (R=2, W=2)...

✓ All 25 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Bench] Performing 100 Writes and 100 Reads...
[Result] Balanced (R=2, W=2): Write=12.43ms, Read=4.72ms
[Teardown] Stopping cluster...

[Setup] Cleaning environment...

[Test] Testing Config: Strong (R=3, W=3)...

✓ All 25 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/15 seconds...
    10/15 seconds...
    15/15 seconds...
[Bench] Performing 100 Writes and 100 Reads...
[Result] Strong (R=3, W=3): Write=12.52ms, Read=5.02ms
[Teardown] Stopping cluster...

[Graph] Saved plot to graph_report/graph_cost_for_consistency.png

============================================================
TEST R: Background Replication Lag
Objective: Visualize the 'Window of Vulnerability'
============================================================

[Setup] Cleaning environment...

✓ All 100 nodes started
  Hint Interval: 30s
  Waiting for cluster stabilization...
    5/20 seconds...
    10/20 seconds...
    15/20 seconds...
    20/20 seconds...
Added node localhost:50159 with 150 virtual nodes
Added node localhost:50108 with 150 virtual nodes
Added node localhost:50151 with 150 virtual nodes
Added node localhost:50099 with 150 virtual nodes
Added node localhost:50068 with 150 virtual nodes
Added node localhost:50143 with 150 virtual nodes
Added node localhost:50116 with 150 virtual nodes
Added node localhost:50061 with 150 virtual nodes
Added node localhost:50109 with 150 virtual nodes
Added node localhost:50152 with 150 virtual nodes
Added node localhost:50090 with 150 virtual nodes
Added node localhost:50117 with 150 virtual nodes
Added node localhost:50075 with 150 virtual nodes
Added node localhost:50149 with 150 virtual nodes
Added node localhost:50120 with 150 virtual nodes
Added node localhost:50128 with 150 virtual nodes
Added node localhost:50129 with 150 virtual nodes
Added node localhost:50146 with 150 virtual nodes
Added node localhost:50062 with 150 virtual nodes
Added node localhost:50141 with 150 virtual nodes
Added node localhost:50145 with 150 virtual nodes
Added node localhost:50101 with 150 virtual nodes
Added node localhost:50112 with 150 virtual nodes
Added node localhost:50132 with 150 virtual nodes
Added node localhost:50142 with 150 virtual nodes
Added node localhost:50150 with 150 virtual nodes
Added node localhost:50140 with 150 virtual nodes
Added node localhost:50130 with 150 virtual nodes
Added node localhost:50091 with 150 virtual nodes
Added node localhost:50106 with 150 virtual nodes
Added node localhost:50095 with 150 virtual nodes
Added node localhost:50135 with 150 virtual nodes
Added node localhost:50124 with 150 virtual nodes
Added node localhost:50073 with 150 virtual nodes
Added node localhost:50102 with 150 virtual nodes
Added node localhost:50060 with 150 virtual nodes
Added node localhost:50127 with 150 virtual nodes
Added node localhost:50119 with 150 virtual nodes
Added node localhost:50155 with 150 virtual nodes
Added node localhost:50070 with 150 virtual nodes
Added node localhost:50122 with 150 virtual nodes
Added node localhost:50133 with 150 virtual nodes
Added node localhost:50069 with 150 virtual nodes
Added node localhost:50080 with 150 virtual nodes
Added node localhost:50079 with 150 virtual nodes
Added node localhost:50092 with 150 virtual nodes
Added node localhost:50157 with 150 virtual nodes
